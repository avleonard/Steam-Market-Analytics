{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b77faee2",
   "metadata": {},
   "source": [
    "# Predicting Steam Game Review Scores  \n",
    "\n",
    "The goal of this project is to analyze **whether structured attributes carry predictive power when predicting game reviews.**  \n",
    "\n",
    "Some of the key questions I aim to answer are:  \n",
    "\n",
    "- ðŸ¤– **Predictive Power:** How effectively can structured attributes predict game reviews?\n",
    "- ðŸ’¡ **Interpretability:** What are the most influential features? What can they tell us about player satisfaction?  \n",
    "- ðŸš« **Insight Through Failure:** What are the least influential features? What do weak correlations mean?\n",
    "- ðŸ” **Human Predictability:** What does this suggest about how predictable, or unpredictable, human sentiment data truly is?    \n",
    "  \n",
    "---\n",
    "\n",
    "### ðŸ“Š Modeling & Methodology  \n",
    "\n",
    "1ï¸âƒ£ **Target Definition:** Categorize review scores into classes: *High*, *Medium*, and *Low*, based on rating distributions.\n",
    "\n",
    "2ï¸âƒ£ **Feature Engineering:** Transform Steam data into model ready features: log-scaled review counts, log-scaled release prices, and release (year, month, season).  \n",
    "\n",
    "3ï¸âƒ£ **Model Development:** Train and evaluate a Random Forest to test predictability.  \n",
    "\n",
    "4ï¸âƒ£ **Evaluation & Insights:** Use model performance to determine if structured attributes meaningfully predict review outcomes, and identify which features carry the most predictive weight.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235fc541",
   "metadata": {},
   "source": [
    "## Section 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8acdf0a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# scikit-learn modules\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\avleo\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\seaborn\\__init__.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcategorical\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmatrix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmiscplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01maxisgrid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\avleo\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\seaborn\\matrix.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hierarchy\n\u001b[32m     12\u001b[39m     _no_scipy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\avleo\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\scipy\\cluster\\__init__.py:27\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03m=========================================\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mClustering package (:mod:`scipy.cluster`)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     25\u001b[39m __all__ = [\u001b[33m'\u001b[39m\u001b[33mvq\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhierarchy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vq, hierarchy\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_testutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PytestTester\n\u001b[32m     30\u001b[39m test = PytestTester(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\avleo\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\scipy\\cluster\\vq.py:77\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_api_extra \u001b[38;5;28;01mas\u001b[39;00m xpx\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspatial\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cdist\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _vq\n\u001b[32m     79\u001b[39m __docformat__ = \u001b[33m'\u001b[39m\u001b[33mrestructuredtext\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     81\u001b[39m __all__ = [\u001b[33m'\u001b[39m\u001b[33mwhiten\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mvq\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mkmeans\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mkmeans2\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:648\u001b[39m, in \u001b[36mModuleSpec.parent\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    644\u001b[39m \u001b[38;5;129m@cached\u001b[39m.setter\n\u001b[32m    645\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached\u001b[39m(\u001b[38;5;28mself\u001b[39m, cached):\n\u001b[32m    646\u001b[39m     \u001b[38;5;28mself\u001b[39m._cached = cached\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparent\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    650\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"The name of the module's parent.\"\"\"\u001b[39;00m\n\u001b[32m    651\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.submodule_search_locations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Start by importing necessary libraries. \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "# scikit-learn modules\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (accuracy_score, f1_score, classification_report, confusion_matrix, balanced_accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c017a",
   "metadata": {},
   "source": [
    "To get started, we'll import the dataset for this analysis. It can be found inside the .zip folder of this notebook, or, on kaggle.com at: https://www.kaggle.com/datasets/benjaminlundkvist/steam-sales-historical-dataset. \n",
    "\n",
    "- **DISCLAIMER**: Dataset updates weekly on Kaggle. This notebook is built using the dataset that was updated on September 29th, 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e8e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & prepare data.\n",
    "steam_sales = pd.read_csv('steam_sales_Sep28.csv')\n",
    "\n",
    "# Column names & row quantity. \n",
    "print(\"Columns:\", list(steam_sales.columns))\n",
    "print(\"Rows:\", steam_sales.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e886f986",
   "metadata": {},
   "source": [
    "First, we'll check for null and duplicate values, as well as the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e7681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null and duplicate values. \n",
    "print(\"Nulls:\", steam_sales.isnull().values.any())\n",
    "print(\"Duplicates:\", steam_sales[steam_sales['Game Name'].duplicated(keep=False)].values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cac668",
   "metadata": {},
   "source": [
    "Data is pulled directly from the Steam API and refreshed weekly, so the absence of null values and the presence of duplicates are both expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb6772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types.\n",
    "print(steam_sales.dtypes.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8636bcd1",
   "metadata": {},
   "source": [
    "Reviews, Release Date, and Fetched At are stored as objects (strings). #Reviews will be converted to numeric, as it represents quantitative data. \n",
    "\n",
    "Release Date and Fetched At will be converted to datetime to take advantage of pandasâ€™ time and date functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Reviews to numeric. \n",
    "steam_sales['#Reviews'] = pd.to_numeric(steam_sales['#Reviews'].str.replace(',', ''))\n",
    "\n",
    "# Convert Fetched At to datetime.\n",
    "steam_sales['Fetched At'] = pd.to_datetime(steam_sales['Fetched At'])\n",
    "\n",
    "# Convert Release Date to datetime.  \n",
    "date_format_1 = pd.to_datetime(steam_sales['Release Date'], errors='coerce', format = '%b %d, %Y').dropna() # Month Day, Year.\n",
    "date_format_2 = pd.to_datetime(steam_sales['Release Date'], errors='coerce', format = '%d %b, %Y').dropna() # Day Month, Year. (Only used by 1st refresh)\n",
    "steam_sales['Release Date'] = pd.concat([date_format_2, date_format_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3362d096",
   "metadata": {},
   "source": [
    "Duplicate values are likely a consequence of the dataset's weekly updates, where new data is appended, rather than resetting each week. \n",
    "\n",
    "Not all games are tracked each week however, some games may have no duplicates while others might have multiple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c3b1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter duplicates.\n",
    "steam_sales = steam_sales.sort_values('Fetched At', ascending = False)\n",
    "steam_sales = steam_sales.drop_duplicates(subset=['Game Name'], keep='first')\n",
    "steam_sales = steam_sales.reset_index(drop=True)\n",
    "\n",
    "# Check for nulls and duplicates once more.\n",
    "print(\"Nulls:\", steam_sales.isnull().values.any())\n",
    "print(\"Duplicates:\", steam_sales[steam_sales['Game Name'].duplicated(keep=False)].values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885b7d3e",
   "metadata": {},
   "source": [
    "Duplicate values gone! We did this using Fetched At to sort recent updates to the top, then, keeping only the first iteration, dropping values with identical names.\n",
    "\n",
    "Before moving on, let's preview the changes and call `.describe()` to get a sense of what we're about to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad9b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview and description of cleaned dataset. \n",
    "display(steam_sales.head(3))\n",
    "display(steam_sales.describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01380a5f",
   "metadata": {},
   "source": [
    "# Section 2: Creating Analysis Variables\n",
    "\n",
    "Now that our data is clean, we can define the variables we'll be modeling on. These will go into a new dataframe exclusively for analysis variables. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59314576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating analysis variables dataframe.\n",
    "analysis_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47440da8",
   "metadata": {},
   "source": [
    "The data description suggests a potential skew, so we'll start by examining the Original Price (â‚¬) and #Reviews features to check whether they require transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7cb8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for Original Price.\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.hist(steam_sales['Original Price (â‚¬)'], bins=50, color='salmon', edgecolor='black')\n",
    "ax.set_xlabel('Original Price (â‚¬)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Original Price')\n",
    "plt.savefig('output/hist_original_price.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf91a64c",
   "metadata": {},
   "source": [
    "Game prices cluster towards â‚¬20, with the highest at â‚¬100. The distribution isn't severely skewed, but it could hurt the model's results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for #Reviews.\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.hist(steam_sales['#Reviews'], bins=50, color='skyblue', edgecolor='black')\n",
    "ax.set_xlabel('Number of Reviews (in millions)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Reviews')\n",
    "plt.savefig('output/hist_reviews.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c835def9",
   "metadata": {},
   "source": [
    "Reviews, however, has a severe skew. With a max value at over a million and most games not even approaching 100,000, this needs to be transformed. \n",
    "\n",
    "To ensure values aren't ignored while others get overvalued, both features will be using log-transformed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6189c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transformed #Reviews.\n",
    "analysis_df['Log Reviews'] = np.log1p(steam_sales['#Reviews'])\n",
    "\n",
    "# Log-transformed Original Price.\n",
    "analysis_df['Log Price'] = np.log1p(steam_sales['Original Price (â‚¬)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b82ad17",
   "metadata": {},
   "source": [
    "From Release Date, we'll be using Year for annual trends, and Month to analyze the impact of release timing.\n",
    "\n",
    "We'll also use Discount% and operating system support, flipping Discounts from negative to positive, and adding OS Support as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df710bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year & Month as features.\n",
    "analysis_df['Year'] = steam_sales['Release Date'].dt.year\n",
    "analysis_df['Month'] = steam_sales['Release Date'].dt.month\n",
    "\n",
    "# Positive Discount% values.\n",
    "analysis_df['Discount'] = steam_sales['Discount%'].abs()\n",
    "\n",
    "# Add OS Support columns.\n",
    "analysis_df['Windows'] = steam_sales['Windows']\n",
    "analysis_df['Linux'] = steam_sales['Linux']\n",
    "analysis_df['MacOS'] = steam_sales['MacOS']\n",
    "analysis_df['OS_Count'] = analysis_df[['Windows','Linux','MacOS']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b051c",
   "metadata": {},
   "source": [
    "To use ratings as a target variable, the scale needs clarification. Steam displays reviews as 9 different text categories, while the data represents them numerically, from 3.0 to 8.0.\n",
    "\n",
    "By cross-referencing several titles with their Steam store pages, the following mapping emerges:\n",
    "\n",
    "- 3.0: *Mostly Negative*\n",
    "- 4.0: *Mixed*\n",
    "- 5.0: *Mostly Positive*\n",
    "- 6.0: *Positive*\n",
    "- 7.0: *Very Positive*\n",
    "- 8.0: *Overwhelmingly Positive*\n",
    "\n",
    "Extremely low ratings, (below 3.0) are absent in the data. Likely the result of a filter, games *this* bad often carry extreme quality issues or customer deception.\n",
    "\n",
    "For our target variable, scores are grouped into three classes:\n",
    "- *Low* (3.0â€“4.0), *Medium* (5.0â€“6.0), and *High* (7.0â€“8.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b5068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target classes: *Low*, *Medium*, *High*. \n",
    "analysis_df['Review_Category'] = pd.cut(steam_sales['Rating'], bins=[2.5, 4.5, 6.5, 8.5], labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# Verify analysis variables dataframe. \n",
    "analysis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e20a1c7",
   "metadata": {},
   "source": [
    "Dataframe looks ready! Before continuing, we'll verify class distribution since exceptionally poor ratings, which make up a large number of releases, are absent. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2de0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution.\n",
    "class_counts = analysis_df['Review_Category'].value_counts().sort_index()\n",
    "bars = plt.bar(class_counts.index, class_counts.values, color='skyblue', edgecolor='black')\n",
    "plt.bar_label(bars)\n",
    "plt.savefig('output/class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Percent of data with *High* reviews. \n",
    "print(\"Class distribution (%):\")\n",
    "print((analysis_df['Review_Category'].value_counts(normalize=True) * 100).round(2).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f6f1b",
   "metadata": {},
   "source": [
    "This carries a glaring class imbalance, with almost 70% of data belonging to 1 of 3 classes. \n",
    "\n",
    "Moving forward, we'll create and deploy training sets to evaluate balanced data and unbalanced as a benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f23d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target.\n",
    "X = analysis_df.drop(columns=[\"Review_Category\"])\n",
    "y = analysis_df[\"Review_Category\"]\n",
    "\n",
    "# Split into train and test sets.\n",
    "split_amount = 0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_amount, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f30d0",
   "metadata": {},
   "source": [
    "We'll balance our data by resampling each class with SMOTE to have the same number of values. \n",
    "\n",
    "It's important to strike a fair balance between undersampling and oversampling. *Low* and *Medium* need greater representation, but we don't want to squash our *High* data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd0ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Combine X_train and y_train.\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Split into class subsets.\n",
    "high_df = train_df[train_df[\"Review_Category\"] == \"High\"]\n",
    "med_df  = train_df[train_df[\"Review_Category\"] == \"Medium\"]\n",
    "low_df  = train_df[train_df[\"Review_Category\"] == \"Low\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b4778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample *High* class to 900.\n",
    "high_resample = resample(high_df, replace=False, n_samples=900, random_state=42)\n",
    "\n",
    "# Recombine with Medium and Low.\n",
    "train_balanced = pd.concat([high_resample, med_df, low_df])\n",
    "\n",
    "# Separate back into X and y.\n",
    "X_bal = train_balanced.drop(columns=[\"Review_Category\"])\n",
    "y_bal = train_balanced[\"Review_Category\"]\n",
    "\n",
    "# Oversample *Low* & *Medium* classes. \n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_bal, y_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf5449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify balanced distribution.\n",
    "print(y_train_bal.value_counts().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ab462",
   "metadata": {},
   "source": [
    "Classes have been resampled to contain the same number of values (900).\n",
    "\n",
    "- The *High* class was randomly reduced to 900 samples to prevent it from dominating the model.\n",
    "- The *Medium* and *Low* classes were oversampled to 900 each using SMOTE.\n",
    "\n",
    "We're using SMOTE, as it preserves the integrity of the data by generating new, realistic samples based on learned patterns. While imperfect, we need lots of synthetic data, and having a significant amount of duplicate data could have major consequences. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b256f6",
   "metadata": {},
   "source": [
    "# Section 3: Creating Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620fddb2",
   "metadata": {},
   "source": [
    "##### **Random Forest Classifier**\n",
    "\n",
    "- Captures non-linear relationships and handles both continuous and categorical features with minimal preprocessing.\n",
    "- Reduces overfitting and remains stable even with noisy or synthetic (SMOTE) data. \n",
    "\n",
    "We'll test two versions: one with unbalanced data and weighted classes, and another with balanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81d6a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest on unbalanced data, & weighted classes.\n",
    "rf_unbalanced = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "rf_unbalanced.fit(X_train, y_train)\n",
    "\n",
    "# Train Random Forest on balanced data.\n",
    "rf_balanced = RandomForestClassifier(random_state=42)\n",
    "rf_balanced.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Unbalanced Accuracy & Classification Report.\n",
    "y_pred = rf_unbalanced.predict(X_test)\n",
    "print(\"\\nUnbalanced Classification Report:\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "# Balanced Accuracy & Classification Report.\n",
    "y_pred_bal = rf_balanced.predict(X_test)\n",
    "print(\"\\nBalanced Classification Report:\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(classification_report(y_test, y_pred_bal))\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb774fe9",
   "metadata": {},
   "source": [
    "From an initial analysis using classification reports: balancing the data noticeably decreased accuracy, but moderately improved *Low* & *Medium* performance. \n",
    "\n",
    "For further clarity on how the models differ, we'll create a confusion matrix heatmap for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcdaae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for side by side comparison.\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Unbalanced model confusion matrix.\n",
    "cm_unbalanced = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm_unbalanced, annot=True, fmt='d', cmap='Blues', xticklabels=['High', 'Low', 'Medium'], yticklabels=['High', 'Low', 'Medium'], ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix - Unbalanced Model')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "# Balanced model confusion matrix.\n",
    "cm_balanced = confusion_matrix(y_test, y_pred_bal)\n",
    "sns.heatmap(cm_balanced, annot=True, fmt='d', cmap='Greens', xticklabels=['High', 'Low', 'Medium'], yticklabels=['High', 'Low', 'Medium'], ax=axes[1])\n",
    "axes[1].set_title('Confusion Matrix - Balanced Model')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "\n",
    "plt.savefig('output/confusion_matrices.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291b739",
   "metadata": {},
   "source": [
    "The unbalanced model heavily favors the *High* class, with almost no color in or recognition of *Low* or *Medium* tiles.\n",
    "\n",
    "The balanced model still greatly favors *High*, but predictions are more evenly distributed, improving minority-class performance at the cost of accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d69fa74",
   "metadata": {},
   "source": [
    "##### **Random Forest Interpretation**\n",
    "\n",
    "Unbalanced Model: (higher overall accuracy, biased to majority)\n",
    "- Accuracy 0.72, driven by very high recall on *High* (0.96).\n",
    "- Minority classes suffer: *Low* recall 0.17, *Medium* recall 0.16.\n",
    "- Macro F1 = 0.44, showing poor average per-class performance.\n",
    "\n",
    "Balanced Model: (fairer across classes, lower accuracy)\n",
    "- Accuracy drops to 0.60 as the model no longer over focuses on *High*.\n",
    "- Minority class recall improves: *Low* 0.40, *Medium* 0.34.\n",
    "- Macro F1 = 0.46 and macro recall = 0.48, showing more equitable performance.\n",
    "\n",
    "Trade-offs:\n",
    "- Unbalanced: higher overall accuracy, weak minority detection, best for maximizing accuracy on the majority class.\n",
    "- Balanced: stronger class balance, lower accuracy, best if the goal involves the minority classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e871fa",
   "metadata": {},
   "source": [
    "# Section 4: Feature Importance\n",
    "To further interpret the results, and understand how our model is being built, we'll take a look at what features are actually making an impact.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dbc4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances for visualization and comparison.\n",
    "rf_unbalanced_fi = pd.Series(rf_unbalanced.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "rf_balanced_fi = pd.Series(rf_balanced.feature_importances_, index=X_train_bal.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising Unbalanced Feature Importance.\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.barh(rf_unbalanced_fi.sort_values(ascending=True).index, rf_unbalanced_fi.sort_values(ascending=True).values, color=\"steelblue\")\n",
    "\n",
    "# Add value annotations to bars.\n",
    "plt.bar_label(bars, fmt='%.3f', fontsize=9)\n",
    "\n",
    "plt.title(\"Feature Importance - Unbalanced Model\")\n",
    "plt.xlabel(\"Importance\")\n",
    "\n",
    "plt.savefig('output/barh_feature_importance_unbalanced.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365d8b2e",
   "metadata": {},
   "source": [
    "The unbalanced model heavily relies on popularity (Log Reviews). Log Price, Discount, Month, and Year, are all moderately impactful, but without reviews, predictive power would be minimal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325ca2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising Balanced Feature Importance.\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.barh(rf_balanced_fi.sort_values(ascending=True).index, rf_balanced_fi.sort_values(ascending=True).values, color=\"seagreen\")\n",
    "\n",
    "# Add value annotations to bars.\n",
    "plt.bar_label(bars, fmt='%.3f', fontsize=9)\n",
    "\n",
    "plt.title(\"Feature Importance - Balanced Model\")\n",
    "plt.xlabel(\"Importance\")\n",
    "\n",
    "plt.savefig('output/barh_feature_importance_balanced.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bbc814",
   "metadata": {},
   "source": [
    "With the balanced model, reliance on Log Reviews is reduced, and feature importance is distributed a little more evenly. The distribution overall looks much more uniform and usable than unbalanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7436784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature importance DataFrame.\n",
    "unbal_series = pd.Series(rf_unbalanced.feature_importances_, index=X_train.columns, name=\"Unbalanced\")\n",
    "bal_series = pd.Series(rf_balanced.feature_importances_, index=X_train_bal.columns, name=\"Balanced\")\n",
    "all_feats = unbal_series.index.union(bal_series.index)\n",
    "fi_df = pd.concat([unbal_series.reindex(all_feats), bal_series.reindex(all_feats)], axis=1)\n",
    "fi_df[\"Difference\"] = fi_df[\"Balanced\"] - fi_df[\"Unbalanced\"] # Adding difference column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comprehensive dataframe. \n",
    "print(\"---------- Feature Importance Data ---------------\\n \")\n",
    "print(fi_df)\n",
    "print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd13e5b5",
   "metadata": {},
   "source": [
    "Feature Importance:\n",
    "- Log Reviews is the strongest predictor, but its influence drops after balancing.\n",
    "- Log Price and Discount gain importance post-balancing, suggesting price/discount are more impactful once the class bias is reduced.\n",
    "- Month & Year are moderately impactful, with small decreases indicating modest seasonality/temporal effects.\n",
    "- OS features are minimally impactful overall; MacOS slightly ticks up, but remains minor. Windows, Linux, and OS_Support_Count are negligible.\n",
    "\n",
    "Insights & Takeaways:\n",
    "- With unbalanced data, the model leans heavily on engagement/popularity (Log Reviews). After balancing, it spreads importance toward pricing and discounting, implying these factors better differentiate Medium/Low vs High when class bias is controlled.\n",
    "- Many predictors here are pleasantly surprising. While OS support proved nearly redundant, I anticipated predictive power would come almost exclusively from Log Reviews and Discount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a948276e",
   "metadata": {},
   "source": [
    "# Section 5: Additional Models\n",
    "\n",
    "Before concluding, weâ€™ll briefly run a few alternative classifiers. Itâ€™s important to verify that Random Forest isnâ€™t the only model producing certain results. The goal isnâ€™t to fully tune or optimize these models, but to ensure our findings arenâ€™t unique to one algorithm, and that we chose the right model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aab54cc",
   "metadata": {},
   "source": [
    "##### **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d7f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression.\n",
    "log_reg = LogisticRegression(max_iter=100000, class_weight='balanced', random_state=42) \n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "\n",
    "print(\"\\nLogReg Classification Report:\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc9ce36",
   "metadata": {},
   "source": [
    "- Performs noticeably worse than Random Forest. While it achieves high precision on the *High* class, recall is poor, accuracy is poor, and performance on the minority classes remained weak. \n",
    "- Overall accuracy and macro F1 show the model struggled to capture the complexity of the data compared to a Random Forest.\n",
    "- Raised a convergence warning at 1000 iterations. For a fairer comparison, increased the iteration limit to 100000. While not the central focus, this ensured stable results without a warning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294d6b72",
   "metadata": {},
   "source": [
    "##### **K-Nearest Neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a57e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Classifier. \n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "print(\"\\nKNN Classification Report:\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d9dd90",
   "metadata": {},
   "source": [
    "- While it achieves strong recall on the *High* class, precision and recall are very poor on the minority classes.\n",
    "- Overall accuracy (0.67) looks decent, but the low macro F1 (0.37) shows that it fails to generalize across classes, relying heavily on the dominant class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ef9dc7",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The goal of this project was to analyze whether structured attributes have predictive power when predicting game reviews using Steam sales data. Through machine learning analysis, we've determined that these variables *do* carry, although limited, predictive weight.\n",
    "\n",
    "**Key Findings:** Random Forest models achieved meaningful predictive performance:\n",
    "- Unbalanced Model: 72% accuracy with strong recall on majority class (*High* reviews: 96%).\n",
    "- Balanced Model: 60% accuracy with more equitable performance across all classes.\n",
    "- Macro F1 scores: 0.44 (unbalanced) vs 0.46 (balanced), showing balanced model's superior class generalization.\n",
    "- Comparators: Logistic Regression and KNN confirmed the pattern, both leaned on the majority class and underperformed RF on macro F1.\n",
    "\n",
    "**Feature Interpretability:**\n",
    "- Log Reviews: (32.2% â†’ 28.1% importance) - Player engagement is the strongest predictor.\n",
    "- Log Price: (19.4% â†’ 22.0% importance) - Pricing strategy significantly impacts reviews.\n",
    "- Discount: (15.7% â†’ 17.7% importance) - Sales promotions affect, or reflect, player sentiment.\n",
    "- Month/Year: (14.3% / 12.8% importance) - Release patterns do matter.\n",
    "\n",
    "**Human Predictability:** Moderate performance suggests human sentiment has both predictable and unpredictable elements:\n",
    "- Predictable aspects: Engagement metrics, pricing, and temporal factors show clear patterns.\n",
    "- Unpredictable aspects: The remaining 28-40% error suggests factors like game quality, genre preferences, marketing effectiveness, and individual taste variations.\n",
    "\n",
    "**Limitations & Next Steps:**\n",
    "\n",
    "- Minority classes remain hard; rely on macro/weighted F1 and confusion matrices, not accuracy alone.\n",
    "- Add more features (genre, developer reputation, text reviews).\n",
    "- Create visuals for alternative models, and explore them further. \n",
    "\n",
    "**Refrences**\n",
    "- Dataset on Kaggle (updated weekly): https://www.kaggle.com/datasets/benjaminlundkvist/steam-sales-historical-dataset.\n",
    "- Steam store: https://store.steampowered.com/\n",
    "- SMOTE: https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html\n",
    "- matplotlib bar_label: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar_label.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
